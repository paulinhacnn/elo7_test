{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protective-carroll",
   "metadata": {
    "id": "protective-carroll"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df3 = pd.read_csv('elo7_recruitment_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "guilty-album",
   "metadata": {
    "id": "guilty-album"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "    '''\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input : Pandas dataframe\n",
    "        Input dataframe to be split.\n",
    "    stratify_colname : str\n",
    "        The name of the column that will be used for stratification. Usually\n",
    "        this column would be for the label.\n",
    "    frac_train : float\n",
    "    frac_val   : float\n",
    "    frac_test  : float\n",
    "        The ratios with which the dataframe will be split into train, val, and\n",
    "        test data. The values should be expressed as float fractions and should\n",
    "        sum to 1.0.\n",
    "    random_state : int, None, or RandomStateInstance\n",
    "        Value to be passed to train_test_split().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train, df_val, df_test :\n",
    "        Dataframes containing the three splits.\n",
    "    '''\n",
    "\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
    "\n",
    "    X = df_input # Contains all columns.\n",
    "    # y = category \n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "posted-machine",
   "metadata": {
    "id": "posted-machine"
   },
   "outputs": [],
   "source": [
    "train, validate, test = split_stratified_into_train_val_test(df3, stratify_colname='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qualified-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rodar apenas uma vez\n",
    "#!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helpful-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-circle",
   "metadata": {
    "id": "appreciated-circle"
   },
   "outputs": [],
   "source": [
    "# https://www.elo7.com.br/bolsa-de-praia-pink-de-tela-barca/dp/195E09?e7src=home&e7mdm=card#bn=1\n",
    "textos = [\"Sapatinho Corujinha\", \"Kit de Sapatinhos com luva\", \"Sapatinho Allstar Tenis\"]\n",
    "texto = \"Sapatinho Corujinha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "preliminary-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suitable-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_title = (title.lower() for title in df3[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "motivated-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7fb4f01a8b48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords, alphanumber and phrases with 3 words\n",
    "def treat_words(doc):\n",
    "    valid_tokens = []\n",
    "    for token in doc:\n",
    "        e_valid = not token.is_stop and token.is_alpha\n",
    "        if e_valid:\n",
    "            valid_tokens.append(token.text)\n",
    "    if len(valid_tokens) > 1:\n",
    "        return \" \".join(valid_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fifteen-coast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9595110654830933\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "time_initial= time()\n",
    "\n",
    "treated_text = [treat_words(doc) for doc in nlp.pipe(treatment_title, batch_size=1000)]\n",
    "\n",
    "time_process = time() - time_initial\n",
    "print(time_process/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "canadian-legend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38507\n"
     ]
    }
   ],
   "source": [
    "print(len(treated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "boolean-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22364\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "treated_titles = pd.DataFrame({\"title\": treated_text}).dropna().drop_duplicates()\n",
    "print(len(treated_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "micro-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "failing-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiperparameters\n",
    "#sg = continuos bag 0 of words and skip-gram 1\n",
    "# window = context representation word2vec\n",
    "# min_count = typing error\n",
    "# neural network with layer\n",
    "# alpha = learning rate , leave the maximum point and go to the minimum point \n",
    "# min_alpha = decay\n",
    "w2v_model = Word2Vec(sg=0, window = 2, size=300, min_count=5, alpha=0.03, min_alpha=0.007 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eligible-czech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fb4f0111b70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "impaired-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat sentences (list of list of tokens -> title)\n",
    "sentences = list_list_tokens = [title.split(\" \") for title in treated_titles.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exceptional-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:48,623 : - collecting all words and their counts\n",
      "2021-03-01 04:12:48,624 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-03-01 04:12:48,630 : - PROGRESS: at sentence #5000, processed 19327 words, keeping 3019 word types\n",
      "2021-03-01 04:12:48,635 : - PROGRESS: at sentence #10000, processed 39196 words, keeping 4275 word types\n",
      "2021-03-01 04:12:48,641 : - PROGRESS: at sentence #15000, processed 59411 words, keeping 5313 word types\n",
      "2021-03-01 04:12:48,646 : - PROGRESS: at sentence #20000, processed 79987 words, keeping 6094 word types\n",
      "2021-03-01 04:12:48,650 : - collected 6466 word types from a corpus of 89778 raw words and 22364 sentences\n",
      "2021-03-01 04:12:48,651 : - Loading a fresh vocabulary\n",
      "2021-03-01 04:12:48,657 : - min_count=5 retains 2057 unique words (31% of original 6466, drops 4409)\n",
      "2021-03-01 04:12:48,657 : - min_count=5 leaves 82681 word corpus (92% of original 89778, drops 7097)\n",
      "2021-03-01 04:12:48,663 : - deleting the raw counts dictionary of 6466 items\n",
      "2021-03-01 04:12:48,665 : - sample=0.001 downsamples 55 most-common words\n",
      "2021-03-01 04:12:48,666 : - downsampling leaves estimated 69302 word corpus (83.8% of prior 82681)\n",
      "2021-03-01 04:12:48,670 : - estimated required memory for 2057 words and 300 dimensions: 5965300 bytes\n",
      "2021-03-01 04:12:48,671 : - resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level=logging.INFO)\n",
    "# building vocabulary\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=5000)\n",
    "# mensage log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "friendly-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print(\"Loss após a época {}:{}\".format(self.epoch, loss))\n",
    "        else:\n",
    "            print(\"Loss após a época {}:{}\".format(self.epoch, loss-self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "present-lending",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:49,014 : - training model with 3 workers on 2057 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "2021-03-01 04:12:49,064 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,070 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,073 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,074 : - EPOCH - 1 : training on 89778 raw words (69220 effective words) took 0.0s, 1514074 effective words/s\n",
      "2021-03-01 04:12:49,124 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,127 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,133 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,134 : - EPOCH - 2 : training on 89778 raw words (69236 effective words) took 0.1s, 1330533 effective words/s\n",
      "2021-03-01 04:12:49,183 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,186 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,192 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,193 : - EPOCH - 3 : training on 89778 raw words (69219 effective words) took 0.0s, 1474292 effective words/s\n",
      "2021-03-01 04:12:49,246 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,252 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,254 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,255 : - EPOCH - 4 : training on 89778 raw words (69332 effective words) took 0.0s, 1467606 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 0:94297.765625\n",
      "Loss após a época 1:71480.609375\n",
      "Loss após a época 2:65628.875\n",
      "Loss após a época 3:60562.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:49,304 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,307 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,314 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,315 : - EPOCH - 5 : training on 89778 raw words (69312 effective words) took 0.0s, 1434331 effective words/s\n",
      "2021-03-01 04:12:49,364 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,367 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,373 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,374 : - EPOCH - 6 : training on 89778 raw words (69266 effective words) took 0.1s, 1340464 effective words/s\n",
      "2021-03-01 04:12:49,429 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,433 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,438 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,439 : - EPOCH - 7 : training on 89778 raw words (69374 effective words) took 0.1s, 1230643 effective words/s\n",
      "2021-03-01 04:12:49,492 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,498 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,501 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,501 : - EPOCH - 8 : training on 89778 raw words (69346 effective words) took 0.1s, 1295144 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 4:55407.21875\n",
      "Loss após a época 5:51215.46875\n",
      "Loss após a época 6:47605.15625\n",
      "Loss após a época 7:44426.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:49,555 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,563 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,565 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,566 : - EPOCH - 9 : training on 89778 raw words (69326 effective words) took 0.0s, 1560934 effective words/s\n",
      "2021-03-01 04:12:49,620 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,627 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,630 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,630 : - EPOCH - 10 : training on 89778 raw words (69359 effective words) took 0.1s, 1238405 effective words/s\n",
      "2021-03-01 04:12:49,685 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,692 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,695 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,695 : - EPOCH - 11 : training on 89778 raw words (69349 effective words) took 0.0s, 1417254 effective words/s\n",
      "2021-03-01 04:12:49,751 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,755 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,758 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,758 : - EPOCH - 12 : training on 89778 raw words (69208 effective words) took 0.1s, 1294961 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 8:42088.625\n",
      "Loss após a época 9:39953.9375\n",
      "Loss após a época 10:37947.125\n",
      "Loss após a época 11:36220.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:49,813 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,821 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,824 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,825 : - EPOCH - 13 : training on 89778 raw words (69305 effective words) took 0.1s, 1188431 effective words/s\n",
      "2021-03-01 04:12:49,880 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,886 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,889 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,890 : - EPOCH - 14 : training on 89778 raw words (69331 effective words) took 0.1s, 1251052 effective words/s\n",
      "2021-03-01 04:12:49,941 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:49,948 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:49,950 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:49,951 : - EPOCH - 15 : training on 89778 raw words (69161 effective words) took 0.1s, 1275186 effective words/s\n",
      "2021-03-01 04:12:50,002 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,006 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,011 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,012 : - EPOCH - 16 : training on 89778 raw words (69400 effective words) took 0.1s, 1290856 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 12:35138.5\n",
      "Loss após a época 13:33786.875\n",
      "Loss após a época 14:32735.625\n",
      "Loss após a época 15:31912.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:50,060 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,063 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,070 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,070 : - EPOCH - 17 : training on 89778 raw words (69390 effective words) took 0.0s, 1500648 effective words/s\n",
      "2021-03-01 04:12:50,119 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,124 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,128 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,128 : - EPOCH - 18 : training on 89778 raw words (69162 effective words) took 0.0s, 1996475 effective words/s\n",
      "2021-03-01 04:12:50,181 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,186 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,188 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,188 : - EPOCH - 19 : training on 89778 raw words (69308 effective words) took 0.1s, 1345321 effective words/s\n",
      "2021-03-01 04:12:50,240 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,247 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,250 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,250 : - EPOCH - 20 : training on 89778 raw words (69331 effective words) took 0.1s, 1303965 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 16:30858.5625\n",
      "Loss após a época 17:40287.9375\n",
      "Loss após a época 18:29268.0\n",
      "Loss após a época 19:28581.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:50,301 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,307 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,308 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,309 : - EPOCH - 21 : training on 89778 raw words (69439 effective words) took 0.1s, 1384345 effective words/s\n",
      "2021-03-01 04:12:50,363 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,370 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,373 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,373 : - EPOCH - 22 : training on 89778 raw words (69341 effective words) took 0.1s, 1377320 effective words/s\n",
      "2021-03-01 04:12:50,425 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,430 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,434 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,435 : - EPOCH - 23 : training on 89778 raw words (69305 effective words) took 0.1s, 1309098 effective words/s\n",
      "2021-03-01 04:12:50,484 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,490 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,492 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,493 : - EPOCH - 24 : training on 89778 raw words (69314 effective words) took 0.0s, 1398313 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 20:28154.5625\n",
      "Loss após a época 21:27649.6875\n",
      "Loss após a época 22:27063.875\n",
      "Loss após a época 23:35630.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:50,548 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,553 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,559 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,559 : - EPOCH - 25 : training on 89778 raw words (69276 effective words) took 0.1s, 1211609 effective words/s\n",
      "2021-03-01 04:12:50,613 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,619 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,622 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,623 : - EPOCH - 26 : training on 89778 raw words (69348 effective words) took 0.1s, 1223716 effective words/s\n",
      "2021-03-01 04:12:50,676 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,684 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,686 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,686 : - EPOCH - 27 : training on 89778 raw words (69271 effective words) took 0.1s, 1238471 effective words/s\n",
      "2021-03-01 04:12:50,736 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,740 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,746 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,746 : - EPOCH - 28 : training on 89778 raw words (69243 effective words) took 0.0s, 1459674 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 24:26290.625\n",
      "Loss após a época 25:25607.625\n",
      "Loss após a época 26:25243.0\n",
      "Loss após a época 27:24932.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:50,797 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,801 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,807 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,808 : - EPOCH - 29 : training on 89778 raw words (69207 effective words) took 0.1s, 1296689 effective words/s\n",
      "2021-03-01 04:12:50,860 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:50,863 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:50,869 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:50,870 : - EPOCH - 30 : training on 89778 raw words (69166 effective words) took 0.0s, 1545692 effective words/s\n",
      "2021-03-01 04:12:50,870 : - training on a 2693340 raw words (2078845 effective words) took 1.9s, 1120086 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 28:25052.0\n",
      "Loss após a época 29:24456.625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2078845, 2693340)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, compute_loss=True, callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "smaller-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulinhasantos/anaconda3/envs/elo_teste/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "2021-03-01 04:12:50,877 : - precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bebê', 0.7158752679824829),\n",
       " ('cilios', 0.5748425126075745),\n",
       " ('ovelhinhas', 0.5430614948272705),\n",
       " ('ursinhas', 0.5115598440170288),\n",
       " ('soneca', 0.5050129890441895),\n",
       " ('zoe', 0.48289942741394043),\n",
       " ('bebês', 0.4789409637451172),\n",
       " ('coroas', 0.47468453645706177),\n",
       " ('ursa', 0.46888861060142517),\n",
       " ('chevron', 0.4648624658584595)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyse the result, quanlitative\n",
    "w2v_model.most_similar(\"bebe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "appropriate-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulinhasantos/anaconda3/envs/elo_teste/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('noivado', 0.6011864542961121),\n",
       " ('debutante', 0.5665645599365234),\n",
       " ('consagração', 0.5459885001182556),\n",
       " ('madrinhas', 0.5355975031852722),\n",
       " ('madrinha', 0.5047541260719299),\n",
       " ('marsala', 0.48429062962532043),\n",
       " ('padre', 0.48323777318000793),\n",
       " ('padrinho', 0.4812665283679962),\n",
       " ('monograma', 0.4706394672393799),\n",
       " ('batismo', 0.46959495544433594)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"casamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "white-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulinhasantos/anaconda3/envs/elo_teste/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('jantar', 0.8123608827590942),\n",
       " ('moderna', 0.7328689098358154),\n",
       " ('urbana', 0.6977060437202454),\n",
       " ('cachoeira', 0.6966215968132019),\n",
       " ('aula', 0.6833953857421875),\n",
       " ('moderno', 0.6817888617515564),\n",
       " ('cidade', 0.6806402206420898),\n",
       " ('painéis', 0.6763515472412109),\n",
       " ('fofinho', 0.6714497804641724),\n",
       " ('abstrato', 0.6564012765884399)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"decoracao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-deficit",
   "metadata": {},
   "source": [
    "## skip-gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wooden-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:50,907 : - collecting all words and their counts\n",
      "2021-03-01 04:12:50,908 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-03-01 04:12:50,913 : - PROGRESS: at sentence #5000, processed 19327 words, keeping 3019 word types\n",
      "2021-03-01 04:12:50,919 : - PROGRESS: at sentence #10000, processed 39196 words, keeping 4275 word types\n",
      "2021-03-01 04:12:50,924 : - PROGRESS: at sentence #15000, processed 59411 words, keeping 5313 word types\n",
      "2021-03-01 04:12:50,930 : - PROGRESS: at sentence #20000, processed 79987 words, keeping 6094 word types\n",
      "2021-03-01 04:12:50,934 : - collected 6466 word types from a corpus of 89778 raw words and 22364 sentences\n",
      "2021-03-01 04:12:50,935 : - Loading a fresh vocabulary\n",
      "2021-03-01 04:12:50,941 : - min_count=5 retains 2057 unique words (31% of original 6466, drops 4409)\n",
      "2021-03-01 04:12:50,942 : - min_count=5 leaves 82681 word corpus (92% of original 89778, drops 7097)\n",
      "2021-03-01 04:12:50,949 : - deleting the raw counts dictionary of 6466 items\n",
      "2021-03-01 04:12:50,950 : - sample=0.001 downsamples 55 most-common words\n",
      "2021-03-01 04:12:50,950 : - downsampling leaves estimated 69302 word corpus (83.8% of prior 82681)\n",
      "2021-03-01 04:12:50,956 : - estimated required memory for 2057 words and 300 dimensions: 5965300 bytes\n",
      "2021-03-01 04:12:50,957 : - resetting layer weights\n",
      "2021-03-01 04:12:51,293 : - training model with 3 workers on 2057 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-03-01 04:12:51,373 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,383 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,384 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,385 : - EPOCH - 1 : training on 89778 raw words (69350 effective words) took 0.1s, 938165 effective words/s\n",
      "2021-03-01 04:12:51,463 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,472 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,475 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,475 : - EPOCH - 2 : training on 89778 raw words (69264 effective words) took 0.1s, 928755 effective words/s\n",
      "2021-03-01 04:12:51,545 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,563 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,565 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,565 : - EPOCH - 3 : training on 89778 raw words (69259 effective words) took 0.1s, 832121 effective words/s\n",
      "2021-03-01 04:12:51,639 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,657 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,658 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,659 : - EPOCH - 4 : training on 89778 raw words (69307 effective words) took 0.1s, 804342 effective words/s\n",
      "2021-03-01 04:12:51,739 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,752 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,753 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,754 : - EPOCH - 5 : training on 89778 raw words (69235 effective words) took 0.1s, 865730 effective words/s\n",
      "2021-03-01 04:12:51,825 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,840 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,843 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,843 : - EPOCH - 6 : training on 89778 raw words (69209 effective words) took 0.1s, 1013960 effective words/s\n",
      "2021-03-01 04:12:51,913 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:51,930 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:51,931 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:51,932 : - EPOCH - 7 : training on 89778 raw words (69210 effective words) took 0.1s, 909101 effective words/s\n",
      "2021-03-01 04:12:52,004 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,020 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,023 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,023 : - EPOCH - 8 : training on 89778 raw words (69251 effective words) took 0.1s, 838156 effective words/s\n",
      "2021-03-01 04:12:52,094 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,109 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,111 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,112 : - EPOCH - 9 : training on 89778 raw words (69274 effective words) took 0.1s, 860704 effective words/s\n",
      "2021-03-01 04:12:52,182 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,198 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,201 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,201 : - EPOCH - 10 : training on 89778 raw words (69333 effective words) took 0.1s, 835534 effective words/s\n",
      "2021-03-01 04:12:52,273 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,288 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,291 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,292 : - EPOCH - 11 : training on 89778 raw words (69309 effective words) took 0.1s, 831354 effective words/s\n",
      "2021-03-01 04:12:52,368 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,377 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,379 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,380 : - EPOCH - 12 : training on 89778 raw words (69324 effective words) took 0.1s, 1034554 effective words/s\n",
      "2021-03-01 04:12:52,460 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,468 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,469 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,469 : - EPOCH - 13 : training on 89778 raw words (69348 effective words) took 0.1s, 855026 effective words/s\n",
      "2021-03-01 04:12:52,539 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,555 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,558 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,558 : - EPOCH - 14 : training on 89778 raw words (69277 effective words) took 0.1s, 837694 effective words/s\n",
      "2021-03-01 04:12:52,638 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,643 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,646 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,646 : - EPOCH - 15 : training on 89778 raw words (69160 effective words) took 0.1s, 870172 effective words/s\n",
      "2021-03-01 04:12:52,726 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,732 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,735 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,735 : - EPOCH - 16 : training on 89778 raw words (69198 effective words) took 0.1s, 872171 effective words/s\n",
      "2021-03-01 04:12:52,805 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,821 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:52,823 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,824 : - EPOCH - 17 : training on 89778 raw words (69197 effective words) took 0.1s, 851446 effective words/s\n",
      "2021-03-01 04:12:52,902 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:52,910 : - worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:52,911 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:52,912 : - EPOCH - 18 : training on 89778 raw words (69270 effective words) took 0.1s, 1018687 effective words/s\n",
      "2021-03-01 04:12:52,989 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,000 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,003 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,003 : - EPOCH - 19 : training on 89778 raw words (69301 effective words) took 0.1s, 921734 effective words/s\n",
      "2021-03-01 04:12:53,080 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,091 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,093 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,094 : - EPOCH - 20 : training on 89778 raw words (69357 effective words) took 0.1s, 839264 effective words/s\n",
      "2021-03-01 04:12:53,164 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,175 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,182 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,183 : - EPOCH - 21 : training on 89778 raw words (69243 effective words) took 0.1s, 854480 effective words/s\n",
      "2021-03-01 04:12:53,260 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,274 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,276 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,277 : - EPOCH - 22 : training on 89778 raw words (69222 effective words) took 0.1s, 871433 effective words/s\n",
      "2021-03-01 04:12:53,351 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,368 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,370 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,371 : - EPOCH - 23 : training on 89778 raw words (69245 effective words) took 0.1s, 799314 effective words/s\n",
      "2021-03-01 04:12:53,450 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,461 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,464 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,465 : - EPOCH - 24 : training on 89778 raw words (69401 effective words) took 0.1s, 797000 effective words/s\n",
      "2021-03-01 04:12:53,539 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,557 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,559 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,559 : - EPOCH - 25 : training on 89778 raw words (69433 effective words) took 0.1s, 818858 effective words/s\n",
      "2021-03-01 04:12:53,634 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,647 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,650 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,650 : - EPOCH - 26 : training on 89778 raw words (69356 effective words) took 0.1s, 904665 effective words/s\n",
      "2021-03-01 04:12:53,720 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,735 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,738 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,738 : - EPOCH - 27 : training on 89778 raw words (69319 effective words) took 0.1s, 853394 effective words/s\n",
      "2021-03-01 04:12:53,814 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,826 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,828 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,828 : - EPOCH - 28 : training on 89778 raw words (69384 effective words) took 0.1s, 921070 effective words/s\n",
      "2021-03-01 04:12:53,907 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:53,914 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:53,915 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:53,916 : - EPOCH - 29 : training on 89778 raw words (69370 effective words) took 0.1s, 860000 effective words/s\n",
      "2021-03-01 04:12:53,991 : - worker thread finished; awaiting finish of 2 more threads\n",
      "2021-03-01 04:12:54,000 : - worker thread finished; awaiting finish of 1 more threads\n",
      "2021-03-01 04:12:54,003 : - worker thread finished; awaiting finish of 0 more threads\n",
      "2021-03-01 04:12:54,004 : - EPOCH - 30 : training on 89778 raw words (69184 effective words) took 0.1s, 963541 effective words/s\n",
      "2021-03-01 04:12:54,004 : - training on a 2693340 raw words (2078590 effective words) took 2.7s, 767020 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2078590, 2693340)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "w2v_model_skipgram = Word2Vec(sg=1, window = 5, size=300, min_count=5, alpha=0.03, min_alpha=0.007 )\n",
    "\n",
    "w2v_model_skipgram.build_vocab(sentences, progress_per=5000)\n",
    "\n",
    "w2v_model_skipgram.train(sentences, total_examples=w2v_model_skipgram.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eastern-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:54,010 : - precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bebê', 0.5451101660728455),\n",
       " ('ursa', 0.5250155925750732),\n",
       " ('conforto', 0.4950309097766876),\n",
       " ('ursinhas', 0.4945724606513977),\n",
       " ('salmão', 0.493078351020813),\n",
       " ('molhadeira', 0.47946828603744507),\n",
       " ('cilios', 0.4748899042606354),\n",
       " ('termica', 0.4741533696651459),\n",
       " ('cavalinho', 0.4691942036151886),\n",
       " ('detalhes', 0.4610801041126251)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_skipgram.wv.most_similar(\"bebe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "referenced-bobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('noivado', 0.6201376914978027),\n",
       " ('debutante', 0.49689939618110657),\n",
       " ('madrinha', 0.4903338551521301),\n",
       " ('marsala', 0.4892551898956299),\n",
       " ('padre', 0.48681971430778503),\n",
       " ('pastor', 0.48036718368530273),\n",
       " ('chanfrada', 0.47239524126052856),\n",
       " ('noivinhos', 0.47019630670547485),\n",
       " ('noivos', 0.4700844883918762),\n",
       " ('sachês', 0.46872368454933167)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_skipgram.wv.most_similar(\"casamento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-accessory",
   "metadata": {},
   "source": [
    "# Conclusão\n",
    "##### acesso: https://www.elo7.com.br\n",
    "\n",
    "No caso de casamento ele retornou anatômica, diamantada, chanfrada e banhada no modelo skip gram que tem uma grande relacao visto que estão conectadas com a palavra alianca. E salmão existem categorias de lembracas para bebes que tb há cor slamao e muito presente. Assim devido a alta associacao (analogia) da cor com o produto para bebe, o mesmo é coerente apresentando-se como similar.\n",
    "No caso de cílios \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "numerical-maple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:04:56,630 : - storing 2057x300 projection weights into model_cbow.txt\n"
     ]
    }
   ],
   "source": [
    "# save model cbow\n",
    "w2v_model.wv.save_word2vec_format(\"model_cbow.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lesbian-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:04:57,016 : - storing 2057x300 projection weights into model_skip.txt\n"
     ]
    }
   ],
   "source": [
    "#save model skipgram\n",
    "w2v_model.wv.save_word2vec_format(\"model_skip.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-engagement",
   "metadata": {},
   "source": [
    "## Classificacao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "casual-ministry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-01 04:12:54,028 : - loading projection weights from model_cbow.txt\n",
      "2021-03-01 04:12:54,565 : - loaded (2057, 300) matrix from model_cbow.txt\n",
      "2021-03-01 04:12:54,566 : - loading projection weights from model_skip.txt\n",
      "2021-03-01 04:12:55,086 : - loaded (2057, 300) matrix from model_skip.txt\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w2v_model_cbow = KeyedVectors.load_word2vec_format(\"model_cbow.txt\")\n",
    "w2v_model_skipgram = KeyedVectors.load_word2vec_format(\"model_skip.txt\")\n",
    "nlp = spacy.load(\"pt_core_news_sm\", desable=[\"parser\", \"ner\", \"tagger\", \"textcat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "documentary-tracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lembrancinha', 'bebe']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizator(text):\n",
    "    doc=nlp(text)\n",
    "    valid_tokens = []\n",
    "    for token in doc:\n",
    "        e_valid = not token.is_stop and token.is_alpha\n",
    "        if e_valid:\n",
    "            valid_tokens.append(token.text.lower())\n",
    "    return valid_tokens\n",
    "text = \"Lembrancinha de bebe\"\n",
    "tokenizator(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "announced-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48902056  0.15874362  0.71528174  0.12056345 -0.28467058  0.38668891\n",
      "  -0.79554945 -1.15319693  0.00908354  0.46041317 -0.52874875 -0.17413667\n",
      "   0.96144239 -0.03772259  0.21295898  0.49685426 -0.03949238  0.02232021\n",
      "  -0.52251077 -0.17097783  0.26269599 -0.91722532  0.88429809  0.91393304\n",
      "  -0.38189344  0.6398657   0.20920087  0.26544115  0.71789706 -0.64221151\n",
      "   0.07061724  0.23736247  0.73625942 -0.20027842 -0.69149977 -0.0625457\n",
      "  -0.38376166 -0.78147647  0.70572029  0.87022521 -0.39797583 -0.22129533\n",
      "  -0.99756154 -0.68547675 -0.74170688 -0.49795833  0.13850313 -0.0627453\n",
      "   0.48682062 -0.96437243 -0.04397185  0.51269831 -0.17870842 -0.19219952\n",
      "  -0.6738137   1.09459797 -0.10180173 -0.3089267   0.51626769  0.54721735\n",
      "  -1.19467172  0.13622061  1.43469761  0.92820504  0.96610698  0.17531562\n",
      "  -0.14196912  0.11893156 -0.88577314 -0.3827794  -0.45923327  0.65416265\n",
      "  -0.13287787  0.12161149  1.09356011  0.53783652  0.76647489 -0.66384074\n",
      "  -0.10909276  0.28180647 -0.43026483 -0.24122675  0.62929693  0.1200117\n",
      "  -0.31353454 -0.71628633  0.55061495  0.28622994 -1.18167374 -0.55666807\n",
      "  -0.06699921 -0.29055259  0.0975841  -0.11710045 -0.60365543  0.49947217\n",
      "   0.09139626 -0.1416702   0.59260468 -0.7405673   0.67454177  0.08354872\n",
      "  -0.4569096  -0.15311676 -0.15526903 -0.47549323 -0.52193429 -1.27711052\n",
      "  -0.07001089 -0.28961977  0.26558659  1.25534093  0.40110287  0.57744584\n",
      "   0.18318297 -0.61483852 -0.35935816 -1.30585515 -0.08582155 -0.09521277\n",
      "  -0.55216071  0.76185625 -0.03614406  0.07275244 -1.32016945  0.56705008\n",
      "   0.13878344  1.31464267 -0.40596549  0.26257105 -0.38146597 -0.31029347\n",
      "  -0.12077697 -0.3337     -0.01233207 -0.029906    0.1602926  -0.10865876\n",
      "  -0.21480874 -0.17872239  0.38519828 -0.22765902  0.15647541 -0.18690915\n",
      "   0.3042046   0.07165304  0.19160471  0.64588156 -0.37570348 -0.63565783\n",
      "   0.83218771 -0.154343    0.52559312 -0.82113177  0.17331726  0.0869095\n",
      "  -0.89555863  0.20023578  1.1875056  -0.88040568 -0.73366721 -0.36568403\n",
      "   0.22991568  1.13107407 -0.651894    0.39154124  0.66232662 -0.71101992\n",
      "   0.06597584  0.64177841  0.47554509  0.3444474  -0.00270228 -0.10082647\n",
      "  -0.16147497 -0.15577354  0.43752208  0.18830309 -1.66957468 -0.42490801\n",
      "  -0.14893883  0.79806703  0.17282353  0.53841285 -0.52268437  0.71857376\n",
      "   0.60297045 -0.54353249  1.28826946  0.42447984 -0.72131423 -0.60748727\n",
      "   0.96664827 -0.21313878 -0.30725376  0.14911673 -0.30233166 -0.69376842\n",
      "  -0.28684275  0.00279889 -0.66317217  1.27590121 -0.18216493  0.21803816\n",
      "   0.3336441  -0.50683409  0.18353835  0.31563272  0.16792233 -0.53629127\n",
      "  -0.68074965 -1.56826842 -0.64626974  1.02617598  0.39649671  0.79299843\n",
      "  -0.21049415  1.1780299   0.86354738  0.25067403 -0.78828166 -0.39787759\n",
      "  -0.22131285  0.53991903  0.72130103  0.79860717  0.39873193  0.2410645\n",
      "  -0.36600557  0.68176344  0.03758053 -0.12071602  0.41869161  0.75963742\n",
      "   1.2127336   0.76568487  1.24105445  0.8133013  -0.52289665 -0.15386271\n",
      "  -0.39301724  0.50152178 -0.26960556 -0.20286943  0.33144686  0.65934996\n",
      "   0.39605945 -0.3253442   1.11460364 -0.09427902 -0.47496276  0.56438509\n",
      "   0.11281873 -0.39223798  0.14697203  0.4505226   0.1253587  -0.30124632\n",
      "  -0.95526707  0.34644079 -1.16125819  0.60154694  0.86330611 -0.79693386\n",
      "  -0.27688348 -0.60438481 -0.29454233  0.45096836 -0.19890097 -0.4696819\n",
      "   0.62353875 -0.17204273 -0.55835608  0.86776738 -0.88438287 -0.5761261\n",
      "  -0.4361959   0.84949982 -0.10771799  0.69501039  0.98362672  0.08977656\n",
      "   0.12373729  0.10839224 -0.65842304 -0.73112184  0.33160904  0.81363463\n",
      "   0.02458552 -1.91486776 -0.18299534  0.25271501 -0.99936673  0.30613427\n",
      "   0.21929584  0.1702747  -0.32552009 -0.66424438  1.08145051 -0.18546398]]\n",
      "[[-0.48902056  0.15874362  0.71528174  0.12056345 -0.28467058  0.38668891\n",
      "  -0.79554945 -1.15319693  0.00908354  0.46041317 -0.52874875 -0.17413667\n",
      "   0.96144239 -0.03772259  0.21295898  0.49685426 -0.03949238  0.02232021\n",
      "  -0.52251077 -0.17097783  0.26269599 -0.91722532  0.88429809  0.91393304\n",
      "  -0.38189344  0.6398657   0.20920087  0.26544115  0.71789706 -0.64221151\n",
      "   0.07061724  0.23736247  0.73625942 -0.20027842 -0.69149977 -0.0625457\n",
      "  -0.38376166 -0.78147647  0.70572029  0.87022521 -0.39797583 -0.22129533\n",
      "  -0.99756154 -0.68547675 -0.74170688 -0.49795833  0.13850313 -0.0627453\n",
      "   0.48682062 -0.96437243 -0.04397185  0.51269831 -0.17870842 -0.19219952\n",
      "  -0.6738137   1.09459797 -0.10180173 -0.3089267   0.51626769  0.54721735\n",
      "  -1.19467172  0.13622061  1.43469761  0.92820504  0.96610698  0.17531562\n",
      "  -0.14196912  0.11893156 -0.88577314 -0.3827794  -0.45923327  0.65416265\n",
      "  -0.13287787  0.12161149  1.09356011  0.53783652  0.76647489 -0.66384074\n",
      "  -0.10909276  0.28180647 -0.43026483 -0.24122675  0.62929693  0.1200117\n",
      "  -0.31353454 -0.71628633  0.55061495  0.28622994 -1.18167374 -0.55666807\n",
      "  -0.06699921 -0.29055259  0.0975841  -0.11710045 -0.60365543  0.49947217\n",
      "   0.09139626 -0.1416702   0.59260468 -0.7405673   0.67454177  0.08354872\n",
      "  -0.4569096  -0.15311676 -0.15526903 -0.47549323 -0.52193429 -1.27711052\n",
      "  -0.07001089 -0.28961977  0.26558659  1.25534093  0.40110287  0.57744584\n",
      "   0.18318297 -0.61483852 -0.35935816 -1.30585515 -0.08582155 -0.09521277\n",
      "  -0.55216071  0.76185625 -0.03614406  0.07275244 -1.32016945  0.56705008\n",
      "   0.13878344  1.31464267 -0.40596549  0.26257105 -0.38146597 -0.31029347\n",
      "  -0.12077697 -0.3337     -0.01233207 -0.029906    0.1602926  -0.10865876\n",
      "  -0.21480874 -0.17872239  0.38519828 -0.22765902  0.15647541 -0.18690915\n",
      "   0.3042046   0.07165304  0.19160471  0.64588156 -0.37570348 -0.63565783\n",
      "   0.83218771 -0.154343    0.52559312 -0.82113177  0.17331726  0.0869095\n",
      "  -0.89555863  0.20023578  1.1875056  -0.88040568 -0.73366721 -0.36568403\n",
      "   0.22991568  1.13107407 -0.651894    0.39154124  0.66232662 -0.71101992\n",
      "   0.06597584  0.64177841  0.47554509  0.3444474  -0.00270228 -0.10082647\n",
      "  -0.16147497 -0.15577354  0.43752208  0.18830309 -1.66957468 -0.42490801\n",
      "  -0.14893883  0.79806703  0.17282353  0.53841285 -0.52268437  0.71857376\n",
      "   0.60297045 -0.54353249  1.28826946  0.42447984 -0.72131423 -0.60748727\n",
      "   0.96664827 -0.21313878 -0.30725376  0.14911673 -0.30233166 -0.69376842\n",
      "  -0.28684275  0.00279889 -0.66317217  1.27590121 -0.18216493  0.21803816\n",
      "   0.3336441  -0.50683409  0.18353835  0.31563272  0.16792233 -0.53629127\n",
      "  -0.68074965 -1.56826842 -0.64626974  1.02617598  0.39649671  0.79299843\n",
      "  -0.21049415  1.1780299   0.86354738  0.25067403 -0.78828166 -0.39787759\n",
      "  -0.22131285  0.53991903  0.72130103  0.79860717  0.39873193  0.2410645\n",
      "  -0.36600557  0.68176344  0.03758053 -0.12071602  0.41869161  0.75963742\n",
      "   1.2127336   0.76568487  1.24105445  0.8133013  -0.52289665 -0.15386271\n",
      "  -0.39301724  0.50152178 -0.26960556 -0.20286943  0.33144686  0.65934996\n",
      "   0.39605945 -0.3253442   1.11460364 -0.09427902 -0.47496276  0.56438509\n",
      "   0.11281873 -0.39223798  0.14697203  0.4505226   0.1253587  -0.30124632\n",
      "  -0.95526707  0.34644079 -1.16125819  0.60154694  0.86330611 -0.79693386\n",
      "  -0.27688348 -0.60438481 -0.29454233  0.45096836 -0.19890097 -0.4696819\n",
      "   0.62353875 -0.17204273 -0.55835608  0.86776738 -0.88438287 -0.5761261\n",
      "  -0.4361959   0.84949982 -0.10771799  0.69501039  0.98362672  0.08977656\n",
      "   0.12373729  0.10839224 -0.65842304 -0.73112184  0.33160904  0.81363463\n",
      "   0.02458552 -1.91486776 -0.18299534  0.25271501 -0.99936673  0.30613427\n",
      "   0.21929584  0.1702747  -0.32552009 -0.66424438  1.08145051 -0.18546398]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def combinator_vector_sum(words, model=w2v_model_cbow):\n",
    "    result_vector = np.zeros((1, 300))\n",
    "    for w in words:\n",
    "        try:\n",
    "            result_vector += model.get_vector(w)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return result_vector\n",
    "\n",
    "text = \"Lembrancinha de bebe\"\n",
    "words = combinator_vector_sum(tokenizator(text))\n",
    "print(words)\n",
    "words = combinator_vector_sum(tokenizator(text), model=w2v_model_skipgram)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "forbidden-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_matrix(texts, model):\n",
    "    x = len(texts)\n",
    "    matrix = np.zeros((x, 300))\n",
    "    \n",
    "    for i in range(x):\n",
    "        words = tokenizator(texts.iloc[i])\n",
    "        matrix[i] = combinator_vector_sum(words, model)\n",
    "    return matrix\n",
    "#cbow\n",
    "matrix_train_c = vector_matrix(train.title, w2v_model_cbow)\n",
    "matrix_test_c = vector_matrix(test.title, w2v_model_cbow)\n",
    "\n",
    "#skip-gram\n",
    "matrix_train_s = vector_matrix(train.title, w2v_model_skipgram)\n",
    "matrix_test_s = vector_matrix(test.title, w2v_model_skipgram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "gorgeous-ceremony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03865575, -0.44828025,  0.64353627, ..., -0.56104386,\n",
       "         0.79147726, -0.40429975],\n",
       "       [-1.86183476,  0.25833577,  0.03335893, ...,  2.09046109,\n",
       "         1.48261529,  1.24519221],\n",
       "       [-0.48368124,  0.48375386,  0.15157415, ..., -0.94684323,\n",
       "        -0.35266843, -0.47060202],\n",
       "       ...,\n",
       "       [-2.36711238, -1.12889016,  0.21085365, ..., -0.87698052,\n",
       "         1.4759222 ,  0.78756371],\n",
       "       [-0.73387601,  0.02592593,  0.05637543, ...,  0.06413649,\n",
       "        -0.26428528,  0.67564253],\n",
       "       [-1.04010919, -0.15677229,  0.39932306, ..., -0.48496409,\n",
       "         0.50353448, -0.92219686]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_train_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "accepted-folks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "              Bebê       0.87      0.79      0.82      1756\n",
      "Bijuterias e Jóias       0.86      0.89      0.88       238\n",
      "         Decoração       0.84      0.87      0.85      2212\n",
      "     Lembrancinhas       0.84      0.92      0.88      4440\n",
      "            Outros       0.69      0.33      0.45       287\n",
      "       Papel e Cia       0.75      0.56      0.64       694\n",
      "\n",
      "       avg / total       0.84      0.84      0.83      9627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def classification(model, x_train, y_train, x_test, y_test):\n",
    "    LR = LogisticRegression(max_iter=4000)\n",
    "    LR.fit(x_train, y_train)\n",
    "    category = LR.predict(x_test)\n",
    "    result = classification_report(y_test, category)\n",
    "    print(result)\n",
    "    return LR\n",
    "\n",
    "LR_Cbow = classification(w2v_model_cbow, matrix_train_c, train.category, matrix_test_c, test.category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "german-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "              Bebê       0.87      0.79      0.82      1756\n",
      "Bijuterias e Jóias       0.86      0.89      0.88       238\n",
      "         Decoração       0.84      0.87      0.85      2212\n",
      "     Lembrancinhas       0.84      0.92      0.88      4440\n",
      "            Outros       0.69      0.33      0.45       287\n",
      "       Papel e Cia       0.75      0.56      0.64       694\n",
      "\n",
      "       avg / total       0.84      0.84      0.83      9627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_skip = classification(w2v_model_skipgram, matrix_train_s, train.category, matrix_test_s, test.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def classification(model, x_train, y_train, x_test, y_test):\n",
    "    SVC_c = SVC(kernel='linear')\n",
    "    SVC_c.fit(x_train, y_train)\n",
    "    category = SVC_c.predict(x_test)\n",
    "    result = classification_report(y_test, category)\n",
    "    c_m = confusion_matrix(validation.category, category)\n",
    "    print(result)\n",
    "    print(c_m)\n",
    "    return SVC_c\n",
    "\n",
    "SVC_C_Cbow = classification(w2v_model_cbow, matrix_train_c, train.category, matrix_test_c, test.category)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-security",
   "metadata": {},
   "source": [
    "# Aqui temos um recall muito semmelhante a base de dados do ICMC-USP, e com uma base muito menor e ainda com menos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"LR_cbow.pkl\", \"wb\") as f:\n",
    "    pickle.dump(LR_Cbow)\n",
    "    \n",
    "with open(\"LR_skip.pkl\", \"wb\") as f:\n",
    "    pickle.dump(LR_skip)    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
